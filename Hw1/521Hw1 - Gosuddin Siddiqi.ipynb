{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1 Regression\n",
    "**Due Date: 10/16/2017**\n",
    "\n",
    "Name: Gosuddin Siddiqi <br>\n",
    "Student Number: 1627383"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using PyPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Linear Regression\n",
    "Fill in the blanks to implement gradient descent algorithm to solve linear regression problem,\n",
    "$$\\min_x f_{\\text{linear}}(x):=\\frac{1}{2}\\|\\mathbf{F}x - \\mathbf{r}\\|^2 + \\frac{\\lambda}{2}\\|x\\|^2.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct linear regression data\n",
    "srand(123);\n",
    "σ = 0.05;\n",
    "m_linear = 500;\n",
    "n_linear = 100;\n",
    "F_linear = randn(m_linear,n_linear);\n",
    "xt_linear = randn(n_linear);\n",
    "r_linear = F_linear*xt_linear + σ*randn(m_linear);\n",
    "λ_linear = 0.01;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "∇f_linear (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define functions\n",
    "function f_linear(x)\n",
    "    return 0.5*sumabs2(F_linear*x - r_linear) + 0.5*λ_linear*sumabs2(x)\n",
    "end\n",
    "\n",
    "function ∇f_linear(x)\n",
    "    # TODO: calculate and return gradient\n",
    "    g = zeros(x);\n",
    "    g = transpose(F_linear)*(F_linear*(x) - r_linear) + λ_linear*x\n",
    "    return g\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33msumabs2(x) is deprecated, use sum(abs2, x) instead.\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\deprecated.jl:70\u001b[22m\u001b[22m\n",
      " [2] \u001b[1msumabs2\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Float64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\deprecated.jl:57\u001b[22m\u001b[22m\n",
      " [3] \u001b[1mf_linear\u001b[22m\u001b[22m at \u001b[1m.\\In[6]:3\u001b[22m\u001b[22m [inlined]\n",
      " [4] \u001b[1mmacro expansion\u001b[22m\u001b[22m at \u001b[1m.\\In[7]:20\u001b[22m\u001b[22m [inlined]\n",
      " [5] \u001b[1manonymous\u001b[22m\u001b[22m at \u001b[1m.\\<missing>:?\u001b[22m\u001b[22m\n",
      " [6] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\loading.jl:515\u001b[22m\u001b[22m\n",
      " [7] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Module, ::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\sony\\.julia\\v0.6\\Compat\\src\\Compat.jl:464\u001b[22m\u001b[22m\n",
      " [8] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\sony\\.julia\\v0.6\\IJulia\\src\\execute_request.jl:154\u001b[22m\u001b[22m\n",
      " [9] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\sony\\.julia\\v0.6\\IJulia\\src\\eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [10] \u001b[1m(::IJulia.##14#17)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[7], in expression starting on line 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  10, obj 1.82337e+01, err 8.67964e+01\n",
      "iter  20, obj 1.29095e+00, err 9.59764e+00\n",
      "iter  30, obj 1.04717e+00, err 1.40230e+00\n",
      "iter  40, obj 1.04175e+00, err 2.20238e-01\n",
      "iter  50, obj 1.04161e+00, err 3.56522e-02\n",
      "iter  60, obj 1.04161e+00, err 5.87718e-03\n",
      "iter  70, obj 1.04161e+00, err 9.81887e-04\n",
      "iter  80, obj 1.04161e+00, err 1.65830e-04\n",
      "iter  90, obj 1.04161e+00, err 2.82625e-05\n",
      "iter 100, obj 1.04161e+00, err 4.85367e-06\n"
     ]
    }
   ],
   "source": [
    "# Gradient Descent Iteration\n",
    "# TODO: calculate the step size\n",
    "η_linear = 0.0;\n",
    "# initialize variable and parameters\n",
    "x_linear = zeros(n_linear);\n",
    "g_linear = ∇f_linear(x_linear);\n",
    "iterMax = 500;\n",
    "tol = 1e-6;\n",
    "his_linear = zeros(iterMax);\n",
    "beta = norm(F_linear,2)^2 + λ_linear\n",
    "\n",
    "noi = 1;\n",
    "err = Inf;\n",
    "for noi = 1:iterMax\n",
    "    # TODO: gradient descent step \n",
    "    # ...\n",
    "    # update convergence information\n",
    "    x_linear = x_linear - (g_linear/beta)\n",
    "    g_linear = ∇f_linear(x_linear);\n",
    "    obj = f_linear(x_linear);\n",
    "    err = vecnorm(g_linear);\n",
    "    his_linear[noi] = err;\n",
    "    noi%10 == 0 && @printf(\"iter %3d, obj %1.5e, err %1.5e\\n\", noi,obj,err);\n",
    "    err < tol && break;\n",
    "end\n",
    "his_linear = his_linear[1:noi];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vecnorm(xt_linear - x_linear) = 0.027460550066284582\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: semilogy not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: semilogy not defined\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "# compare result\n",
    "@show vecnorm(xt_linear - x_linear);\n",
    "# print convergence history\n",
    "semilogy(his_linear)\n",
    "title(\"convergence history for linear regression\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: LASSO\n",
    "Fill in the blanks to implement proximal gradient descent algorithm to solve LASSO problem,\n",
    "$$\\min_x f_{\\text{lasso}}(x):=\\frac{1}{2}\\|\\mathbf{F}x - \\mathbf{r}\\|^2 + \\lambda\\|x\\|_1.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct LASSO variables\n",
    "srand(123);\n",
    "σ = 0.05;\n",
    "m_lasso = 200;\n",
    "n_lasso = 500;\n",
    "k_lasso = 10;\n",
    "F_lasso = randn(m_lasso,n_lasso);\n",
    "xt_lasso = zeros(n_lasso);\n",
    "for i = randperm(n_lasso)[1:k_lasso]\n",
    "    xt_lasso[i] = rand([-1.0,1.0]);\n",
    "end\n",
    "r_lasso = F_lasso*xt_lasso + σ*randn(m_lasso);\n",
    "λ_lasso = 10.0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prox_1norm (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define functions\n",
    "function f_lasso(x)\n",
    "    return 0.5*sumabs2(F_lasso*x - r_lasso) + λ_lasso*sumabs(x)\n",
    "end\n",
    "\n",
    "function ∇f_lasso_smooth(x)\n",
    "    # TODO: calculate and return gradient\n",
    "    g = zeros(x)\n",
    "    g = transpose(F_lasso)*(F_lasso*x - r_lasso)\n",
    "    return g\n",
    "end\n",
    "\n",
    "function prox_1norm(x, κ)\n",
    "    # TODO: compute the prox operator\n",
    "    y = zeros(x);\n",
    "    i = 1;\n",
    "    for i = 1:length(y)\n",
    "        if x[i] > κ\n",
    "            y[i] = x[i] - κ;\n",
    "        elseif x[i] < -κ\n",
    "            y[i] = x[i] + κ;\n",
    "        else\n",
    "            y[i] = 0;           \n",
    "        end\n",
    "    end\n",
    "    return y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  10, obj 1.97058e+02, err 8.66725e+01\n",
      "iter  20, obj 1.60671e+02, err 5.97826e+01\n",
      "iter  30, obj 1.39079e+02, err 4.88951e+01\n",
      "iter  40, obj 1.23426e+02, err 4.31449e+01\n",
      "iter  50, obj 1.11512e+02, err 3.67088e+01\n",
      "iter  60, obj 1.03297e+02, err 2.93384e+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33msumabs2(x) is deprecated, use sum(abs2, x) instead.\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\deprecated.jl:70\u001b[22m\u001b[22m\n",
      " [2] \u001b[1msumabs2\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Float64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\deprecated.jl:57\u001b[22m\u001b[22m\n",
      " [3] \u001b[1mmacro expansion\u001b[22m\u001b[22m at \u001b[1m.\\In[37]:24\u001b[22m\u001b[22m [inlined]\n",
      " [4] \u001b[1manonymous\u001b[22m\u001b[22m at \u001b[1m.\\<missing>:?\u001b[22m\u001b[22m\n",
      " [5] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\loading.jl:515\u001b[22m\u001b[22m\n",
      " [6] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Module, ::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\sony\\.julia\\v0.6\\Compat\\src\\Compat.jl:464\u001b[22m\u001b[22m\n",
      " [7] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\sony\\.julia\\v0.6\\IJulia\\src\\execute_request.jl:154\u001b[22m\u001b[22m\n",
      " [8] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\sony\\.julia\\v0.6\\IJulia\\src\\eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [9] \u001b[1m(::IJulia.##14#17)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[37], in expression starting on line 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  70, obj 9.89641e+01, err 1.84687e+01\n",
      "iter  80, obj 9.77111e+01, err 8.49211e+00\n",
      "iter  90, obj 9.74923e+01, err 3.41651e+00\n",
      "iter 100, obj 9.74651e+01, err 9.70558e-01\n",
      "iter 110, obj 9.74628e+01, err 2.98437e-01\n",
      "iter 120, obj 9.74626e+01, err 9.25438e-02\n",
      "iter 130, obj 9.74626e+01, err 2.88363e-02\n",
      "iter 140, obj 9.74625e+01, err 9.02023e-03\n",
      "iter 150, obj 9.74625e+01, err 2.83197e-03\n",
      "iter 160, obj 9.74625e+01, err 8.92400e-04\n",
      "iter 170, obj 9.74625e+01, err 2.82268e-04\n",
      "iter 180, obj 9.74625e+01, err 8.96254e-05\n",
      "iter 190, obj 9.74625e+01, err 2.85689e-05\n",
      "iter 200, obj 9.74625e+01, err 9.14239e-06\n",
      "iter 210, obj 9.74625e+01, err 2.93706e-06\n",
      "iter 220, obj 9.74625e+01, err 9.47153e-07\n"
     ]
    }
   ],
   "source": [
    "# Proximal Gradient Descent Iteration\n",
    "# TODO: calculate the step size\n",
    "η_lasso = 0.0;\n",
    "# initialize variable and parameters\n",
    "x_lasso = zeros(n_lasso);\n",
    "x_lasso_old = zeros(n_lasso);\n",
    "g_lasso = ∇f_lasso_smooth(x_lasso);\n",
    "iterMax = 500;\n",
    "tol = 1e-6;\n",
    "his_lasso = zeros(iterMax);\n",
    "\n",
    "#step size\n",
    "step = 1.0/(norm(F_lasso,2)^2);\n",
    "\n",
    "noi = 1;\n",
    "err = Inf;\n",
    "for noi = 1:iterMax\n",
    "    # TODO: proximal gradient descent step \n",
    "    # ...\n",
    "    # ...\n",
    "    # update convergence information\n",
    "    g_lasso = ∇f_lasso_smooth(x_lasso);\n",
    "    x_lasso = prox_1norm((x_lasso - (step*g_lasso)), λ_lasso*step )\n",
    "    obj = f_lasso(x_lasso);\n",
    "    err = norm(x_lasso - x_lasso_old,2)/step #/η_lasso;\n",
    "    copy!(x_lasso_old, x_lasso);\n",
    "    his_lasso[noi] = err;\n",
    "    noi%10 == 0 && @printf(\"iter %3d, obj %1.5e, err %1.5e\\n\", noi,obj,err);\n",
    "    err < tol && break;\n",
    "end\n",
    "his_lasso = his_lasso[1:noi];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot result\n",
    "plot(xt_lasso)\n",
    "plot(x_lasso,\"o\")\n",
    "title(\"LASSO result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot convergence history\n",
    "semilogy(his_lasso);\n",
    "title(\"convergence history for LASSO\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Robust Regression\n",
    "Fill in the blanks to implement proximal gradient descent algorithm to solve robust regression problem,\n",
    "$$\\min_x f_{\\text{robust}}(x):=\\rho_\\kappa\\left(\\mathbf{F}x - \\mathbf{r}\\right) + \\lambda\\|x\\|_1.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct Robust Regression variables\n",
    "srand(123);\n",
    "σ = 0.05;\n",
    "m_robust = 200;\n",
    "n_robust = 500;\n",
    "k_robust = 10;\n",
    "F_robust = randn(m_robust,n_robust);\n",
    "xt_robust = zeros(n_robust);\n",
    "for i = randperm(n_robust)[1:k_robust]\n",
    "    xt_robust[i] = rand([-1.0,1.0]);\n",
    "end\n",
    "r_robust = F_robust*xt_robust + σ*randn(m_robust);\n",
    "for i = randperm(m_robust)[1:k_robust]\n",
    "    r_robust[i] += 5.0*randn();\n",
    "end\n",
    "λ_robust = 2.0;\n",
    "κ_robust = 0.1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "∇f_robust_smooth (generic function with 1 method)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define functions\n",
    "function ρ(r)\n",
    "    val = 0.0;\n",
    "    i = 1;\n",
    "    for i = 1:length(r)\n",
    "        if r[i] > κ_robust\n",
    "            val += κ_robust*abs(r[i]) - ((κ_robust^2)/2);\n",
    "        else\n",
    "            val += ((r[i]^2)/2);\n",
    "        end\n",
    "    end\n",
    "    # TODO: return value for Huber function\n",
    "    return val\n",
    "end\n",
    "\n",
    "function f_robust(x)\n",
    "    return ρ(F_robust*x - r_lasso) + λ_robust*sumabs(x)\n",
    "end\n",
    "\n",
    "function ∇f_robust_smooth(x)\n",
    "    # TODO: calculate and return gradient\n",
    "    g = zero(x);\n",
    "    y = F_robust*x - r_robust;\n",
    "    i = 1;\n",
    "    for i = 1:length(y)\n",
    "        if y[i]> κ_robust\n",
    "            g[i] = κ_robust * sign(y[i]);\n",
    "        else\n",
    "            g[i] = y[i];\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    g = transpose(F_robust)*y\n",
    "    return g\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  10, obj 8.40641e+01, err 5.54231e+01\n",
      "iter  20, obj 8.20724e+01, err 2.43419e+01\n",
      "iter  30, obj 7.94768e+01, err 1.89423e+01\n",
      "iter  40, obj 7.71558e+01, err 1.65921e+01\n",
      "iter  50, obj 7.52941e+01, err 1.54862e+01\n",
      "iter  60, obj 7.35349e+01, err 1.41205e+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33msumabs(x) is deprecated, use sum(abs, x) instead.\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\deprecated.jl:70\u001b[22m\u001b[22m\n",
      " [2] \u001b[1msumabs\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Float64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\deprecated.jl:57\u001b[22m\u001b[22m\n",
      " [3] \u001b[1mmacro expansion\u001b[22m\u001b[22m at \u001b[1m.\\In[36]:23\u001b[22m\u001b[22m [inlined]\n",
      " [4] \u001b[1manonymous\u001b[22m\u001b[22m at \u001b[1m.\\<missing>:?\u001b[22m\u001b[22m\n",
      " [5] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\loading.jl:515\u001b[22m\u001b[22m\n",
      " [6] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Module, ::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\sony\\.julia\\v0.6\\Compat\\src\\Compat.jl:464\u001b[22m\u001b[22m\n",
      " [7] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\sony\\.julia\\v0.6\\IJulia\\src\\execute_request.jl:154\u001b[22m\u001b[22m\n",
      " [8] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\sony\\.julia\\v0.6\\IJulia\\src\\eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [9] \u001b[1m(::IJulia.##14#17)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[36], in expression starting on line 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  70, obj 7.20493e+01, err 1.27930e+01\n",
      "iter  80, obj 7.05650e+01, err 1.20755e+01\n",
      "iter  90, obj 6.91721e+01, err 1.13837e+01\n",
      "iter 100, obj 6.79353e+01, err 1.07748e+01\n",
      "iter 110, obj 6.68531e+01, err 1.00552e+01\n",
      "iter 120, obj 6.59290e+01, err 9.36080e+00\n",
      "iter 130, obj 6.50633e+01, err 8.97370e+00\n",
      "iter 140, obj 6.43245e+01, err 8.57069e+00\n",
      "iter 150, obj 6.36057e+01, err 8.04409e+00\n",
      "iter 160, obj 6.29443e+01, err 7.74310e+00\n",
      "iter 170, obj 6.23674e+01, err 7.39817e+00\n",
      "iter 180, obj 6.18412e+01, err 7.13619e+00\n",
      "iter 190, obj 6.13484e+01, err 6.89293e+00\n",
      "iter 200, obj 6.09182e+01, err 6.59939e+00\n",
      "iter 210, obj 6.05484e+01, err 6.34395e+00\n",
      "iter 220, obj 6.02128e+01, err 6.10533e+00\n",
      "iter 230, obj 5.98837e+01, err 5.90608e+00\n",
      "iter 240, obj 5.95660e+01, err 5.77698e+00\n",
      "iter 250, obj 5.92223e+01, err 5.46112e+00\n",
      "iter 260, obj 5.88952e+01, err 5.30438e+00\n",
      "iter 270, obj 5.85846e+01, err 5.18272e+00\n",
      "iter 280, obj 5.83083e+01, err 5.00788e+00\n",
      "iter 290, obj 5.80585e+01, err 4.78611e+00\n",
      "iter 300, obj 5.78059e+01, err 4.60204e+00\n",
      "iter 310, obj 5.75374e+01, err 4.32331e+00\n",
      "iter 320, obj 5.72895e+01, err 4.04072e+00\n",
      "iter 330, obj 5.71016e+01, err 3.76678e+00\n",
      "iter 340, obj 5.69462e+01, err 3.55032e+00\n",
      "iter 350, obj 5.68058e+01, err 3.31754e+00\n",
      "iter 360, obj 5.66984e+01, err 3.06881e+00\n",
      "iter 370, obj 5.66040e+01, err 2.81327e+00\n",
      "iter 380, obj 5.65163e+01, err 2.64159e+00\n",
      "iter 390, obj 5.64503e+01, err 2.44323e+00\n",
      "iter 400, obj 5.63977e+01, err 2.28650e+00\n",
      "iter 410, obj 5.63494e+01, err 2.09481e+00\n",
      "iter 420, obj 5.63030e+01, err 1.94188e+00\n",
      "iter 430, obj 5.62644e+01, err 1.85950e+00\n",
      "iter 440, obj 5.62309e+01, err 1.75362e+00\n",
      "iter 450, obj 5.62062e+01, err 1.66229e+00\n",
      "iter 460, obj 5.61775e+01, err 1.61205e+00\n",
      "iter 470, obj 5.61489e+01, err 1.56910e+00\n",
      "iter 480, obj 5.61115e+01, err 1.45719e+00\n",
      "iter 490, obj 5.60816e+01, err 1.38820e+00\n",
      "iter 500, obj 5.60524e+01, err 1.32049e+00\n",
      "iter 510, obj 5.60187e+01, err 1.27201e+00\n",
      "iter 520, obj 5.59902e+01, err 1.23932e+00\n",
      "iter 530, obj 5.59652e+01, err 1.19816e+00\n",
      "iter 540, obj 5.59416e+01, err 1.15046e+00\n",
      "iter 550, obj 5.59211e+01, err 1.12156e+00\n",
      "iter 560, obj 5.59024e+01, err 1.09904e+00\n",
      "iter 570, obj 5.58857e+01, err 1.08048e+00\n",
      "iter 580, obj 5.58738e+01, err 1.05371e+00\n",
      "iter 590, obj 5.58626e+01, err 1.03497e+00\n",
      "iter 600, obj 5.58514e+01, err 1.01200e+00\n",
      "iter 610, obj 5.58369e+01, err 9.60730e-01\n",
      "iter 620, obj 5.58223e+01, err 8.94985e-01\n",
      "iter 630, obj 5.58107e+01, err 8.59745e-01\n",
      "iter 640, obj 5.58010e+01, err 8.32117e-01\n",
      "iter 650, obj 5.57925e+01, err 8.09022e-01\n",
      "iter 660, obj 5.57864e+01, err 7.84693e-01\n",
      "iter 670, obj 5.57804e+01, err 7.66014e-01\n",
      "iter 680, obj 5.57755e+01, err 7.47590e-01\n",
      "iter 690, obj 5.57708e+01, err 7.29464e-01\n",
      "iter 700, obj 5.57653e+01, err 7.01183e-01\n",
      "iter 710, obj 5.57590e+01, err 6.78734e-01\n",
      "iter 720, obj 5.57521e+01, err 6.61853e-01\n",
      "iter 730, obj 5.57480e+01, err 6.42962e-01\n",
      "iter 740, obj 5.57435e+01, err 6.26702e-01\n",
      "iter 750, obj 5.57401e+01, err 6.05156e-01\n",
      "iter 760, obj 5.57348e+01, err 5.87204e-01\n",
      "iter 770, obj 5.57274e+01, err 5.62666e-01\n",
      "iter 780, obj 5.57198e+01, err 5.45873e-01\n",
      "iter 790, obj 5.57130e+01, err 5.32590e-01\n",
      "iter 800, obj 5.57067e+01, err 5.21362e-01\n",
      "iter 810, obj 5.57009e+01, err 5.11572e-01\n",
      "iter 820, obj 5.56958e+01, err 5.03042e-01\n",
      "iter 830, obj 5.56911e+01, err 4.95391e-01\n",
      "iter 840, obj 5.56866e+01, err 4.88411e-01\n",
      "iter 850, obj 5.56823e+01, err 4.82006e-01\n",
      "iter 860, obj 5.56784e+01, err 4.76076e-01\n",
      "iter 870, obj 5.56747e+01, err 4.70547e-01\n",
      "iter 880, obj 5.56711e+01, err 4.65347e-01\n",
      "iter 890, obj 5.56675e+01, err 4.60425e-01\n",
      "iter 900, obj 5.56652e+01, err 4.52958e-01\n",
      "iter 910, obj 5.56626e+01, err 4.46539e-01\n",
      "iter 920, obj 5.56596e+01, err 4.40727e-01\n",
      "iter 930, obj 5.56566e+01, err 4.35264e-01\n",
      "iter 940, obj 5.56536e+01, err 4.30068e-01\n",
      "iter 950, obj 5.56506e+01, err 4.25093e-01\n",
      "iter 960, obj 5.56476e+01, err 4.20311e-01\n",
      "iter 970, obj 5.56446e+01, err 4.15721e-01\n",
      "iter 980, obj 5.56417e+01, err 4.11296e-01\n",
      "iter 990, obj 5.56388e+01, err 4.07022e-01\n",
      "iter 1000, obj 5.56360e+01, err 4.01725e-01\n"
     ]
    }
   ],
   "source": [
    "# Proximal Gradient Descent Iteration\n",
    "# TODO: calculate the step size\n",
    "η_robust = 0.0;\n",
    "# initialize variable and parameters\n",
    "x_robust = zeros(n_robust);\n",
    "x_robust_old = zeros(n_robust);\n",
    "g_robust = ∇f_robust_smooth(x_robust);\n",
    "iterMax = 1000;\n",
    "tol = 1e-6;\n",
    "his_robust = zeros(iterMax);\n",
    "\n",
    "step =  1.0 / (norm(F_lasso,2)^2)\n",
    "\n",
    "noi = 1;\n",
    "err = Inf;\n",
    "for noi = 1:iterMax\n",
    "    # TODO: gradient descent step \n",
    "    # ...\n",
    "    # ...\n",
    "    # update convergence information\n",
    "    g_robust = ∇f_robust_smooth(x_robust);\n",
    "    x_robust = prox_1norm(x_robust - step*g_robust, λ_robust*step)\n",
    "    obj = f_robust(x_robust);\n",
    "    err = vecnorm(x_robust - x_robust_old)/step;\n",
    "    copy!(x_robust_old, x_robust);\n",
    "    his_robust[noi] = err;\n",
    "    noi%10 == 0 && @printf(\"iter %3d, obj %1.5e, err %1.5e\\n\", noi,obj,err);\n",
    "    err < tol && break;\n",
    "end\n",
    "his_robust = his_robust[1:noi];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot result\n",
    "plot(xt_robust);\n",
    "plot(x_robust,\"o\");\n",
    "title(\"Robust Result\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot convergence history\n",
    "semilogy(his_robust);\n",
    "title(\"convergence history for LASSO\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Logistic Regression\n",
    "Fill in the blanks to implement proximal gradient descent algorithm to solve logistic regression problem,\n",
    "$$\\min_x f_{\\text{logistic}}(x):= \\sum_{i=1}^m\\left\\{\\log\\left(1+\\exp{\\left\\langle f^i, x\\right\\rangle}\\right) - s^i\\left\\langle f^i,x\\right\\rangle\\right\\} + \\frac{\\lambda}{2}\\|x\\|^2$$\n",
    "where $s^i\\in\\{0,1\\}$ indicate the buy or sell.\n",
    "\n",
    "For this problem we will use real data come from [Numerai](https://numer.ai/leaderboard).\n",
    "The data set consist of three parts, train data, validation data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "readdata (generic function with 1 method)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function that read data\n",
    "function readdata(filename, datatype, dsize)\n",
    "    fid = open(filename, \"r\");\n",
    "    data = read(fid, datatype, dsize);\n",
    "    close(fid);\n",
    "    return data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "n_features = 50;\n",
    "m_train = 2000;\n",
    "m_validate = 500;\n",
    "m_test = 500;\n",
    "\n",
    "train_features = readdata(\"numerai_datasets/train_features.bin\", Float64, m_train*n_features);\n",
    "train_target = readdata(\"numerai_datasets/train_target.bin\", Float64, m_train);\n",
    "validate_features = readdata(\"numerai_datasets/validate_features.bin\", Float64, m_validate*n_features);\n",
    "validate_target = readdata(\"numerai_datasets/validate_target.bin\", Float64, m_validate);\n",
    "test_features = readdata(\"numerai_datasets/test_features.bin\", Float64, m_test*n_features);\n",
    "test_target = readdata(\"numerai_datasets/test_target.bin\", Float64, m_test);\n",
    "\n",
    "train_features = reshape(train_features, m_train, n_features);\n",
    "validate_features = reshape(validate_features, m_validate, n_features);\n",
    "test_features = reshape(test_features, m_test, n_features);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Validate Data\n",
    "Doing regression on training data with different $\\lambda$, and test it on the validation data set. Pick the $\\lambda$ that has the smallest error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "∇f_logistic (generic function with 1 method)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define functions\n",
    "function f_logistic(x, λ)\n",
    "    r = train_features*x;\n",
    "    return sum(log(1.0 + exp(r))) - dot(train_target,r) + 0.5*λ*sumabs2(x)\n",
    "end\n",
    "\n",
    "function ∇f_logistic(x, λ)\n",
    "    # TODO: calculate and return gradient\n",
    "    g = zeros(x);\n",
    "    r = train_features*x;\n",
    "    #@show 1.0 ./(1.0 + exp(-r))\n",
    "    g = transpose(train_features)*(1.0 ./ (1.0+exp(-r)) - train_target) + (λ*x)\n",
    "    return g\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logistic_solver (generic function with 1 method)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build solver function\n",
    "# TODO: calculate the step size\n",
    "η_logistic = 0.0;\n",
    "function logistic_solver(x, λ)\n",
    "    # initialize variable and parameters\n",
    "    x⁻ = copy(x);\n",
    "    g  = ∇f_logistic(x, λ);\n",
    "    g⁻ = copy(g);\n",
    "    \n",
    "    step = 1.0 / (vecnorm(train_features)^2 + λ)\n",
    "    \n",
    "    iterMax = 200000;\n",
    "    tol = 1e-6;\n",
    "    his = zeros(iterMax);\n",
    "\n",
    "    noi = 1;\n",
    "    err = Inf;\n",
    "    for noi = 1:iterMax\n",
    "        x = x - step*g;\n",
    "        # update convergence information\n",
    "        g = ∇f_logistic(x, λ);\n",
    "        obj = f_logistic(x, λ);\n",
    "        err = vecnorm(g);\n",
    "        his[noi] = obj;\n",
    "        noi%10000 == 0 && @printf(\"iter %6d, obj %1.5e, err %1.5e\\n\", noi,obj,err);\n",
    "        err < tol && break;\n",
    "    end\n",
    "    his = his[1:noi];\n",
    "    return x, his\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predErr (generic function with 1 method)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict accuracy\n",
    "function predErr(features, target, x)\n",
    "    r = features*x;\n",
    "    val = 0.0;\n",
    "    for I in eachindex(r)\n",
    "        (r[I] > 0.0 && target[I] == 0.0) && (val += 1);\n",
    "        (r[I] < 0.0 && target[I] == 1.0) && (val += 1);\n",
    "    end\n",
    "    return val/length(r);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================ λ = 1.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mexp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\deprecated.jl:70\u001b[22m\u001b[22m\n",
      " [2] \u001b[1mexp\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Float64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\deprecated.jl:57\u001b[22m\u001b[22m\n",
      " [3] \u001b[1m∇f_logistic\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Float64,1}, ::Float64\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\In[73]:12\u001b[22m\u001b[22m\n",
      " [4] \u001b[1mlogistic_solver\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Float64,1}, ::Float64\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\In[74]:7\u001b[22m\u001b[22m\n",
      " [5] \u001b[1mmacro expansion\u001b[22m\u001b[22m at \u001b[1m.\\In[76]:8\u001b[22m\u001b[22m [inlined]\n",
      " [6] \u001b[1manonymous\u001b[22m\u001b[22m at \u001b[1m.\\<missing>:?\u001b[22m\u001b[22m\n",
      " [7] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\loading.jl:515\u001b[22m\u001b[22m\n",
      " [8] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Module, ::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\sony\\.julia\\v0.6\\Compat\\src\\Compat.jl:464\u001b[22m\u001b[22m\n",
      " [9] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\sony\\.julia\\v0.6\\IJulia\\src\\execute_request.jl:154\u001b[22m\u001b[22m\n",
      " [10] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\sony\\.julia\\v0.6\\IJulia\\src\\eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [11] \u001b[1m(::IJulia.##14#17)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[76], in expression starting on line 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  10000, obj 1.35844e+03, err 2.95586e+00\n",
      "iter  20000, obj 1.35703e+03, err 1.12008e+00\n",
      "iter  30000, obj 1.35679e+03, err 5.03897e-01\n",
      "iter  40000, obj 1.35674e+03, err 2.42204e-01\n",
      "iter  50000, obj 1.35673e+03, err 1.19855e-01\n",
      "iter  60000, obj 1.35673e+03, err 6.04228e-02\n",
      "iter  70000, obj 1.35673e+03, err 3.09323e-02\n",
      "iter  80000, obj 1.35673e+03, err 1.60554e-02\n",
      "iter  90000, obj 1.35673e+03, err 8.43884e-03\n",
      "iter 100000, obj 1.35673e+03, err 4.48582e-03\n",
      "iter 110000, obj 1.35673e+03, err 2.40835e-03\n",
      "iter 120000, obj 1.35673e+03, err 1.30418e-03\n",
      "iter 130000, obj 1.35673e+03, err 7.11442e-04\n",
      "iter 140000, obj 1.35673e+03, err 3.90504e-04\n",
      "iter 150000, obj 1.35673e+03, err 2.15453e-04\n",
      "iter 160000, obj 1.35673e+03, err 1.19383e-04\n",
      "iter 170000, obj 1.35673e+03, err 6.63865e-05\n",
      "iter 180000, obj 1.35673e+03, err 3.70263e-05\n",
      "iter 190000, obj 1.35673e+03, err 2.07025e-05\n",
      "iter 200000, obj 1.35673e+03, err 1.15998e-05\n",
      "============================ λ = 1.2\n",
      "iter  10000, obj 1.35543e+03, err 2.66800e-01\n",
      "iter  20000, obj 1.35542e+03, err 1.29278e-01\n",
      "iter  30000, obj 1.35542e+03, err 6.72502e-02\n",
      "iter  40000, obj 1.35541e+03, err 3.60528e-02\n",
      "iter  50000, obj 1.35541e+03, err 1.96894e-02\n",
      "iter  60000, obj 1.35541e+03, err 1.09155e-02\n",
      "iter  70000, obj 1.35541e+03, err 6.13287e-03\n",
      "iter  80000, obj 1.35541e+03, err 3.48765e-03\n",
      "iter  90000, obj 1.35541e+03, err 2.00493e-03\n",
      "iter 100000, obj 1.35541e+03, err 1.16359e-03\n",
      "iter 110000, obj 1.35541e+03, err 6.80890e-04\n",
      "iter 120000, obj 1.35541e+03, err 4.01239e-04\n",
      "iter 130000, obj 1.35541e+03, err 2.37849e-04\n",
      "iter 140000, obj 1.35541e+03, err 1.41695e-04\n",
      "iter 150000, obj 1.35541e+03, err 8.47636e-05\n",
      "iter 160000, obj 1.35541e+03, err 5.08823e-05\n",
      "iter 170000, obj 1.35541e+03, err 3.06327e-05\n",
      "iter 180000, obj 1.35541e+03, err 1.84870e-05\n",
      "iter 190000, obj 1.35541e+03, err 1.11803e-05\n",
      "iter 200000, obj 1.35541e+03, err 6.77352e-06\n",
      "============================ λ = 1.0\n",
      "iter  10000, obj 1.35390e+03, err 3.19174e-01\n",
      "iter  20000, obj 1.35388e+03, err 1.68607e-01\n",
      "iter  30000, obj 1.35387e+03, err 9.51281e-02\n",
      "iter  40000, obj 1.35387e+03, err 5.52253e-02\n",
      "iter  50000, obj 1.35387e+03, err 3.26437e-02\n",
      "iter  60000, obj 1.35387e+03, err 1.95823e-02\n",
      "iter  70000, obj 1.35387e+03, err 1.19025e-02\n",
      "iter  80000, obj 1.35387e+03, err 7.32074e-03\n",
      "iter  90000, obj 1.35387e+03, err 4.55051e-03\n",
      "iter 100000, obj 1.35387e+03, err 2.85488e-03\n",
      "iter 110000, obj 1.35387e+03, err 1.80545e-03\n",
      "iter 120000, obj 1.35387e+03, err 1.14958e-03\n",
      "iter 130000, obj 1.35387e+03, err 7.36170e-04\n",
      "iter 140000, obj 1.35387e+03, err 4.73698e-04\n",
      "iter 150000, obj 1.35387e+03, err 3.06031e-04\n",
      "iter 160000, obj 1.35387e+03, err 1.98374e-04\n",
      "iter 170000, obj 1.35387e+03, err 1.28951e-04\n",
      "iter 180000, obj 1.35387e+03, err 8.40222e-05\n",
      "iter 190000, obj 1.35387e+03, err 5.48584e-05\n",
      "iter 200000, obj 1.35387e+03, err 3.58797e-05\n",
      "============================ λ = 0.8\n",
      "iter  10000, obj 1.35206e+03, err 3.87411e-01\n",
      "iter  20000, obj 1.35203e+03, err 2.23465e-01\n",
      "iter  30000, obj 1.35202e+03, err 1.36889e-01\n",
      "iter  40000, obj 1.35201e+03, err 8.61349e-02\n",
      "iter  50000, obj 1.35201e+03, err 5.51538e-02\n",
      "iter  60000, obj 1.35201e+03, err 3.58292e-02\n",
      "iter  70000, obj 1.35201e+03, err 2.35763e-02\n",
      "iter  80000, obj 1.35201e+03, err 1.56936e-02\n",
      "iter  90000, obj 1.35201e+03, err 1.05538e-02\n",
      "iter 100000, obj 1.35201e+03, err 7.16106e-03\n",
      "iter 110000, obj 1.35201e+03, err 4.89642e-03\n",
      "iter 120000, obj 1.35201e+03, err 3.36986e-03\n",
      "iter 130000, obj 1.35201e+03, err 2.33198e-03\n",
      "iter 140000, obj 1.35201e+03, err 1.62118e-03\n",
      "iter 150000, obj 1.35201e+03, err 1.13136e-03\n",
      "iter 160000, obj 1.35201e+03, err 7.92071e-04\n",
      "iter 170000, obj 1.35201e+03, err 5.56030e-04\n",
      "iter 180000, obj 1.35201e+03, err 3.91221e-04\n",
      "iter 190000, obj 1.35201e+03, err 2.75800e-04\n",
      "iter 200000, obj 1.35201e+03, err 1.94758e-04\n",
      "============================ λ = 0.6\n",
      "iter  10000, obj 1.34978e+03, err 4.79626e-01\n",
      "iter  20000, obj 1.34973e+03, err 3.02732e-01\n",
      "iter  30000, obj 1.34970e+03, err 2.01661e-01\n",
      "iter  40000, obj 1.34969e+03, err 1.37729e-01\n",
      "iter  50000, obj 1.34969e+03, err 9.56589e-02\n",
      "iter  60000, obj 1.34968e+03, err 6.73764e-02\n",
      "iter  70000, obj 1.34968e+03, err 4.80496e-02\n",
      "iter  80000, obj 1.34968e+03, err 3.46489e-02\n",
      "iter  90000, obj 1.34968e+03, err 2.52309e-02\n",
      "iter 100000, obj 1.34968e+03, err 1.85294e-02\n",
      "iter 110000, obj 1.34968e+03, err 1.37070e-02\n",
      "iter 120000, obj 1.34968e+03, err 1.02021e-02\n",
      "iter 130000, obj 1.34968e+03, err 7.63269e-03\n",
      "iter 140000, obj 1.34968e+03, err 5.73506e-03\n",
      "iter 150000, obj 1.34968e+03, err 4.32478e-03\n",
      "iter 160000, obj 1.34968e+03, err 3.27115e-03\n",
      "iter 170000, obj 1.34968e+03, err 2.48052e-03\n",
      "iter 180000, obj 1.34968e+03, err 1.88505e-03\n",
      "iter 190000, obj 1.34968e+03, err 1.43518e-03\n",
      "iter 200000, obj 1.34968e+03, err 1.09442e-03\n",
      "============================ λ = 0.4\n",
      "iter  10000, obj 1.34680e+03, err 6.11242e-01\n",
      "iter  20000, obj 1.34670e+03, err 4.23537e-01\n",
      "iter  30000, obj 1.34665e+03, err 3.07595e-01\n",
      "iter  40000, obj 1.34663e+03, err 2.28562e-01\n",
      "iter  50000, obj 1.34661e+03, err 1.72571e-01\n",
      "iter  60000, obj 1.34660e+03, err 1.32056e-01\n",
      "iter  70000, obj 1.34660e+03, err 1.02255e-01\n",
      "iter  80000, obj 1.34659e+03, err 8.00105e-02\n",
      "iter  90000, obj 1.34659e+03, err 6.31780e-02\n",
      "iter 100000, obj 1.34659e+03, err 5.02795e-02\n",
      "iter 110000, obj 1.34659e+03, err 4.02819e-02\n",
      "iter 120000, obj 1.34659e+03, err 3.24540e-02\n",
      "iter 130000, obj 1.34659e+03, err 2.62705e-02\n",
      "iter 140000, obj 1.34659e+03, err 2.13488e-02\n",
      "iter 150000, obj 1.34659e+03, err 1.74064e-02\n",
      "iter 160000, obj 1.34659e+03, err 1.42313e-02\n",
      "iter 170000, obj 1.34659e+03, err 1.16625e-02\n",
      "iter 180000, obj 1.34659e+03, err 9.57643e-03\n",
      "iter 190000, obj 1.34659e+03, err 7.87698e-03\n",
      "iter 200000, obj 1.34659e+03, err 6.48878e-03\n",
      "============================ λ = 0.2\n",
      "iter  10000, obj 1.34257e+03, err 8.17294e-01\n",
      "iter  20000, obj 1.34238e+03, err 6.25259e-01\n",
      "iter  30000, obj 1.34226e+03, err 4.97506e-01\n",
      "iter  40000, obj 1.34218e+03, err 4.04033e-01\n",
      "iter  50000, obj 1.34213e+03, err 3.33026e-01\n",
      "iter  60000, obj 1.34210e+03, err 2.77936e-01\n",
      "iter  70000, obj 1.34207e+03, err 2.34481e-01\n",
      "iter  80000, obj 1.34205e+03, err 1.99684e-01\n",
      "iter  90000, obj 1.34204e+03, err 1.71426e-01\n",
      "iter 100000, obj 1.34203e+03, err 1.48177e-01\n",
      "iter 110000, obj 1.34202e+03, err 1.28821e-01\n",
      "iter 120000, obj 1.34202e+03, err 1.12534e-01\n",
      "iter 130000, obj 1.34201e+03, err 9.87024e-02\n",
      "iter 140000, obj 1.34201e+03, err 8.68627e-02\n",
      "iter 150000, obj 1.34201e+03, err 7.66592e-02\n",
      "iter 160000, obj 1.34201e+03, err 6.78155e-02\n",
      "iter 170000, obj 1.34200e+03, err 6.01136e-02\n",
      "iter 180000, obj 1.34200e+03, err 5.33790e-02\n",
      "iter 190000, obj 1.34200e+03, err 4.74704e-02\n",
      "iter 200000, obj 1.34200e+03, err 4.22715e-02\n"
     ]
    }
   ],
   "source": [
    "λ_set = [1.4, 1.2, 1.0, 0.8, 0.6, 0.4, 0.2];\n",
    "x_set = fill(ones(n_features), length(λ_set));\n",
    "validate = zeros(λ_set);\n",
    "for i = 1:length(λ_set)\n",
    "    λ = λ_set[i];\n",
    "    println(\"============================ λ = $λ\");\n",
    "    i > 1 && (x_set[i] = copy(x_set[i-1]));\n",
    "    x, his = logistic_solver(x_set[i], λ);\n",
    "    validate[i] = predErr(validate_features, validate_target, x);\n",
    "    x_set[i] = x;\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mval, ind = findmin(validate);\n",
    "x = x_set[ind];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.456"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predErr(test_features, test_target, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus the prediction error is 45.6%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
